# LLM
- [00_LLM_provider.md](../02_KK_AgenticAI/00_LLM_provider.md)

## Overview
- A type of FM specialized in understanding and generating human language
  - Can answer questions, summarize, translate, write code, and more
- eg: 
  - google BERT (similar to GPT but read in both direction)
  - GPT (generative Pretrained Transformer)
     - claude, openAPI gpt family, gemini, perplexity
- backed by **transformer** architecture (older: RNN, LSTM, etc)
  - 2017, use **self-attention mechanism** to understand context and relationships between words in a sentence.
  - helps to process by sentence, not by word
    
## Core components
  - tokens (words/phrase) 
  - embedding(number for token) 
  - vector(define relaton b/w words/token)
  - Vector database (store vectors) + RAG (retrieval augmented generation)

## Life Cycle of FM
```
â­• pre-training
- Data collect : website, book, etc
- Data prep : struture/unstructure(image,etc) + labels, map() + unlabel(input), inheritance pattern, relationship
- Data train with ML alog == ðŸ”ºinitial pre-training
â­• Data evaluation

â­• MODEL ready âœ…

â­• host on cloud (eg: bedrock::amz titan,nova)
use it (inference) - batch + realtime

â­• ðŸ”ºoptimized / Customization  / Continious pre-training
- prompt engineering
- Use adapters / LoRA layers
- retrieval-augmented generation (RAG)
- transfer learning(new layer) |  ðŸ”ºfine tune (some layer) |  re-train (all layer)::rare/$$

>> evaluate again  ( metrics and benchmarks)
Training vs. Validation vs. Test Set

â­• Deploy FM ::
- base(already hosted)
- add delta-layer at runtime, Bedrock will take care.

â­• use it : Make API call to cutom/tuned

â­• Monitoring & Feedback
-  the model's performance is continuously monitored
- feedback is collected from users, domain experts, or other stakeholders
```
---

## Transformer architecture
